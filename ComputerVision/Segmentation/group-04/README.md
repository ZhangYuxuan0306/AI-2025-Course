# äººå·¥æ™ºèƒ½è¯¾ç¨‹ ç¬¬å››ç»„-èåˆæ·±åº¦ä¿¡æ¯çš„å›¾åƒåˆ†å‰²

## ğŸ§  é¡¹ç›®ç®€ä»‹
æœ¬é¡¹ç›®åŸºäºDeepLabv3å®ç°äº†DeepCrackè£‚ç¼æ•°æ®é›†çš„è¯­ä¹‰åˆ†å‰²ï¼Œä»¥åŠåŸºäºMask2Formerå®ç°äº†ç”µå­å…ƒä»¶æ•°æ®é›†çš„å®ä¾‹åˆ†å‰²ï¼›åœ¨æ­¤åŸºç¡€ä¸Šèåˆå¤šç§æ·±åº¦ä¿¡æ¯å¢å¼ºæ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„åˆ†å‰²ç²¾åº¦ï¼Œå®Œæˆä»»åŠ¡ä¹¦çš„æ—¢å®šè¦æ±‚ã€‚

## âš™ï¸ ç¯å¢ƒä¸æ•°æ®å‡†å¤‡
### Requirements
Python 3.7+, CUDA 9.2+, Pytorch 1.8+ \
Our implementation is based on the MMDetection and MMSegmentation.
For more detailed information, please refer to [MMDet](https://mmdetection.readthedocs.io/en/latest/get_started.html) and [MMSeg](https://mmsegmentation.readthedocs.io/en/latest/get_started.html).

### åŸºç¡€ Conda Env 
```
conda creat --name MMLab python=3.8 -y
conda activate MMLab
conda install pytorch torchvision -c pytorch
pip install -U openmim
mim install mmengine
mim install mmcv
```
### å®ä¾‹åˆ†å‰²ä»»åŠ¡ï¼ˆåŸºäºMMDetï¼‰
#### å®¢åˆ¶åŒ–ä½¿ç”¨
```
git clone https://github.com/open-mmlab/mmdetection.git
cd mmdetection
pip install -v -e .
```
1. å°†æ–‡ä»¶å¤¹/customå…¨éƒ¨æ”¾å…¥/mmdetection;
2. å°†Instance_seg/configsä¸­çš„é…ç½®æ”¾å…¥/mmdetection/configsä¸­;
3. é€‚é…åœ°å€
#### æ•°æ®é›†
[ç”µå­å…ƒå™¨ä»¶æ•°æ®é›†](https://bhpan.buaa.edu.cn/link/AA130E079FE9264651B535123EDA2D7790)

### è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ï¼ˆåŸºäºMMSegï¼‰
#### å®¢åˆ¶åŒ–ä½¿ç”¨
```
git clone https://github.com/open-mmlab/mmsegmentation.git
cd mmsegmentation
pip install -v -e .
```
1. å°†Semantic_seg/configsä¸­çš„é…ç½®æ”¾å…¥/mmsegmentation/configsä¸­;
2. å°†Semantic_seg/mmseg/datasetsä¸­çš„æ•°æ®é›†å¤„ç†æ–‡ä»¶æ”¾å…¥/mmsegmentation/mmseg/datasetsä¸­ï¼Œå¹¶ä¿®æ”¹/datasets/__ init __.pyï¼š
```
from .DeepCrack import DeepCrackDataset

__all__ = [
    ......, 'DeepCrackDataset'
]
```
3. é€‚é…åœ°å€

#### æ•°æ®é›†
[DeepCrack-è£‚ç¼æ•°æ®é›†](https://bhpan.buaa.edu.cn/link/AA130E079FE9264651B535123EDA2D7790)

## ğŸ› ï¸ è®­ç»ƒ&æµ‹è¯•Command
### è®­ç»ƒå‘½ä»¤
**Single GPU**
```
python tools/train.py configs/[æ‰€éœ€é…ç½®æ–‡ä»¶].py
```
**Multiple GPU**

```
./tools/dist_train.sh configs/[æ‰€éœ€é…ç½®æ–‡ä»¶].py GPU_NUM
```

### æµ‹è¯•æ–¹æ³•
```
python tools/test.py configs/[æ‰€éœ€é…ç½®æ–‡ä»¶].py [model path] --out [NAME].pkl
```

### æƒé‡è·å–
| Task | Methods | mAP | Weight |
| ---- | ------- | ------ |----- |
| Instance_seg | Baseline | 30.9 | [Link](https://drive.google.com/file/d/14MfED97WzMAyFtSdjSAzqSL6EiL7r2CA/view?usp=drive_link) |
|       | Channel Merge | 41.6 | [Link](https://drive.google.com/file/d/1c3noDtdTyb-zmVh7GcC2QouVK5igKFUa/view?usp=sharing) |
|       | Feature Fusion | 44.4 | [Link](https://drive.google.com/file/d/1Neud97zA-RkWEJV0-nGh0dbOk_8nlYuc/view?usp=sharing) |
|       | Geometric Guidance | 43.3 | [Link](https://drive.google.com/file/d/1jEIXl_d5LZN4ZrssrZG7TSVu7P2r3Cc1/view?usp=drive_link) |
| Semantic_seg | with_load.pth | 76.4 | [Link](https://drive.google.com/file/d/1wTZvPPpYpnCGKBxHZZpvNL50yhhyo1Sx/view?usp=sharing) |
|              | wo_load.pth | 76.1 | [Link](https://drive.google.com/file/d/11XUBG2XhuC36P8UyBSJFWC6Al6--5f3A/view?usp=drive_link) |

## ğŸ“Š æ•ˆæœå±•ç¤º
### å®ä¾‹åˆ†å‰²
<p align="center">
<img src=./Instance_seg/image.jpeg>
</p>

### è¯­ä¹‰åˆ†å‰²
<p align="center">
<img src=./Semantic_seg/image2.jpeg>
</p>

### å‰ç«¯
<p align="center">
<img src=./image3.jpeg>
</p>

## â¤ï¸ è‡´è°¢
* MMdetection: [mmdetection](https://mmdetection.readthedocs.io/en/latest/)
* MMsegmentation: [mmsegmentation](https://mmsegmentation.readthedocs.io/en/latest/)
* Mask2Former: [Code](https://github.com/facebookresearch/Mask2Former); [Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Masked-Attention_Mask_Transformer_for_Universal_Image_Segmentation_CVPR_2022_paper.pdf)
* DFormerv2: [Code](https://github.com/VCIP-RGBD/DFormer); [Paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_DFormerv2_Geometry_Self-Attention_for_RGBD_Semantic_Segmentation_CVPR_2025_paper.pdf)