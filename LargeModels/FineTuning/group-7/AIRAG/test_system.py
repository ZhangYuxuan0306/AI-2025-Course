"""å¿«é€Ÿæµ‹è¯•è„šæœ¬ï¼šéªŒè¯ç³»ç»Ÿå„ç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
import sys
from pathlib import Path
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, level="INFO")

def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    logger.info("æµ‹è¯•1: æ¨¡å—å¯¼å…¥...")
    try:
        import config
        from src.document_loader import DocumentProcessor
        from src.vector_store import VectorStoreManager
        from src.retriever import RetrieverManager
        from src.generator import AnswerGenerator, RAGPipeline
        from src.evaluation import RAGEvaluator, FailureAnalyzer
        logger.success("âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"âœ— æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_document_processing():
    """æµ‹è¯•æ–‡æ¡£å¤„ç†"""
    logger.info("æµ‹è¯•2: æ–‡æ¡£å¤„ç†...")
    try:
        from src.document_loader import DocumentProcessor
        import config
        
        processor = DocumentProcessor(chunk_size=200, chunk_overlap=20)
        
        # æ£€æŸ¥ç¤ºä¾‹æ–‡æ¡£
        docs_path = Path(config.DOCUMENTS_PATH)
        if not docs_path.exists() or not list(docs_path.glob("*.txt")):
            logger.warning("âš  æœªæ‰¾åˆ°ç¤ºä¾‹æ–‡æ¡£ï¼Œè·³è¿‡æ–‡æ¡£åŠ è½½æµ‹è¯•")
            return True
        
        chunks = processor.process_documents(str(docs_path))
        
        if chunks:
            logger.success(f"âœ“ æ–‡æ¡£å¤„ç†æˆåŠŸï¼Œå…± {len(chunks)} ä¸ªæ–‡æ¡£å—")
            logger.info(f"  é¦–ä¸ªæ–‡æ¡£å—é¢„è§ˆ: {chunks[0].page_content[:100]}...")
            return True
        else:
            logger.warning("âš  æœªåŠ è½½åˆ°æ–‡æ¡£å—")
            return True
    
    except Exception as e:
        logger.error(f"âœ— æ–‡æ¡£å¤„ç†å¤±è´¥: {e}")
        return False


def test_embeddings():
    """æµ‹è¯•åµŒå…¥æ¨¡å‹"""
    logger.info("æµ‹è¯•3: åµŒå…¥æ¨¡å‹...")
    try:
        from langchain_huggingface import HuggingFaceEmbeddings
        import config
        
        logger.info(f"  åŠ è½½åµŒå…¥æ¨¡å‹: {config.EMBEDDING_MODEL}")
        embeddings = HuggingFaceEmbeddings(
            model_name=config.EMBEDDING_MODEL,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        # æµ‹è¯•ç¼–ç 
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        vector = embeddings.embed_query(test_text)
        
        logger.success(f"âœ“ åµŒå…¥æ¨¡å‹å·¥ä½œæ­£å¸¸ï¼Œå‘é‡ç»´åº¦: {len(vector)}")
        return True
    
    except Exception as e:
        logger.error(f"âœ— åµŒå…¥æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        logger.info("  æç¤º: é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
        return False


def test_vector_store():
    """æµ‹è¯•å‘é‡æ•°æ®åº“"""
    logger.info("æµ‹è¯•4: å‘é‡æ•°æ®åº“...")
    try:
        from src.document_loader import DocumentProcessor
        from src.vector_store import VectorStoreManager
        from langchain.schema import Document
        import config
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        test_docs = [
            Document(page_content="äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚", metadata={"source": "test"}),
            Document(page_content="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„å­é¢†åŸŸã€‚", metadata={"source": "test"}),
            Document(page_content="æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œã€‚", metadata={"source": "test"}),
        ]
        
        # åˆ›å»ºå‘é‡æ•°æ®åº“
        vs_manager = VectorStoreManager(db_type="faiss")
        vs_manager.create_vectorstore(test_docs)
        
        # æµ‹è¯•æœç´¢
        results = vs_manager.similarity_search("ä»€ä¹ˆæ˜¯AI", k=2)
        
        logger.success(f"âœ“ å‘é‡æ•°æ®åº“å·¥ä½œæ­£å¸¸ï¼Œæ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ")
        return True
    
    except Exception as e:
        logger.error(f"âœ— å‘é‡æ•°æ®åº“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_bm25():
    """æµ‹è¯•BM25æ£€ç´¢å™¨"""
    logger.info("æµ‹è¯•5: BM25æ£€ç´¢å™¨...")
    try:
        from src.retriever import RetrieverManager
        from langchain.schema import Document
        
        test_docs = [
            Document(page_content="äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯", metadata={"source": "test"}),
            Document(page_content="æœºå™¨å­¦ä¹ æ˜¯AIçš„é‡è¦æŠ€æœ¯", metadata={"source": "test"}),
        ]
        
        retriever = RetrieverManager()
        retriever.setup_bm25(test_docs)
        
        results = retriever.retrieve_with_bm25("äººå·¥æ™ºèƒ½", k=1)
        
        logger.success(f"âœ“ BM25æ£€ç´¢å™¨å·¥ä½œæ­£å¸¸ï¼Œæ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ")
        return True
    
    except Exception as e:
        logger.error(f"âœ— BM25æ£€ç´¢å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_llm_connection():
    """æµ‹è¯•LLMè¿æ¥ï¼ˆå¯é€‰ï¼‰"""
    logger.info("æµ‹è¯•6: LLMè¿æ¥...")
    try:
        from src.generator import AnswerGenerator
        import config
        
        if not config.OPENAI_API_KEY or config.OPENAI_API_KEY == "your_api_key_here":
            logger.warning("âš  æœªé…ç½®LLM APIï¼Œè·³è¿‡æµ‹è¯•ï¼ˆä¸å½±å“å…¶ä»–åŠŸèƒ½ï¼‰")
            logger.info("  æç¤º: ç¼–è¾‘ .env æ–‡ä»¶é…ç½® OPENAI_API_KEY")
            return True
        
        generator = AnswerGenerator()
        logger.success("âœ“ LLMåˆå§‹åŒ–æˆåŠŸ")
        return True
    
    except Exception as e:
        logger.warning(f"âš  LLMè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        logger.info("  æç¤º: å¦‚æœä¸ä½¿ç”¨ç”ŸæˆåŠŸèƒ½ï¼Œæ­¤é”™è¯¯å¯ä»¥å¿½ç•¥")
        return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("=" * 60)
    logger.info("RAGé—®ç­”ç³»ç»Ÿ - ç³»ç»Ÿæµ‹è¯•")
    logger.info("=" * 60)
    
    tests = [
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("æ–‡æ¡£å¤„ç†", test_document_processing),
        ("åµŒå…¥æ¨¡å‹", test_embeddings),
        ("å‘é‡æ•°æ®åº“", test_vector_store),
        ("BM25æ£€ç´¢å™¨", test_bm25),
        ("LLMè¿æ¥", test_llm_connection),
    ]
    
    results = []
    for name, test_func in tests:
        try:
            result = test_func()
            results.append((name, result))
        except Exception as e:
            logger.error(f"æµ‹è¯• '{name}' å‡ºç°å¼‚å¸¸: {e}")
            results.append((name, False))
        
        logger.info("")  # ç©ºè¡Œ
    
    # æ€»ç»“
    logger.info("=" * 60)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        logger.info(f"  {name}: {status}")
    
    logger.info(f"\né€šè¿‡ç‡: {passed}/{total} ({passed/total*100:.1f}%)")
    
    if passed == total:
        logger.success("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        logger.info("\nä¸‹ä¸€æ­¥:")
        logger.info("  1. å°†æ–‡æ¡£æ”¾å…¥ data/documents/ ç›®å½•")
        logger.info("  2. è¿è¡Œ 'python run.py --mode web' å¯åŠ¨Webç•Œé¢")
        logger.info("  3. æˆ–è¿è¡Œ 'python run.py --mode cli' å¯åŠ¨å‘½ä»¤è¡Œç•Œé¢")
    elif passed >= total * 0.7:
        logger.warning("\nâš  å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œç³»ç»ŸåŸºæœ¬å¯ç”¨ã€‚")
        logger.info("è¯·æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•é¡¹ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™ã€‚")
    else:
        logger.error("\nâŒ å¤šä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")
        logger.info("\næ•…éšœæ’é™¤:")
        logger.info("  1. ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
        logger.info("  2. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰")
        logger.info("  3. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯å¹¶æ ¹æ®æç¤ºè§£å†³")
        logger.info("  4. å‚è€ƒæ–‡æ¡£: docs/USAGE.md")
    
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

